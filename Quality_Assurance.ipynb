{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b77d6f-45d2-470c-b672-dc4fdff31d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6fdd00-c5fd-46b7-a7ac-2c00b809bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the confusion matrix for each class in y\n",
    "# Arguments:\n",
    "# y_test (numpy.ndarray) --- The y (output) of the test set\n",
    "# y_pred (numpy.ndarray) --- The model's predicted output using X_test\n",
    "# *OPTIONAL* names (list) --- The name of each class\n",
    "def print_confusion_matrix(y_test, y_pred, names=[]):\n",
    "    print(\"CONFUSION MATRICES: ---------------------------------------\")\n",
    "    cm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "    for i in range(len(cm)):\n",
    "        if names:\n",
    "            print(names[i] + ':')\n",
    "        print( \"         PREDICTED 0   PREDICTED 1\" )\n",
    "        print( \"ACTUAL 0    \" + str(cm[i][0][0]) + \"          \" + str(cm[i][0][1]))\n",
    "        print( \"ACTUAL 1    \" + str(cm[i][1][0]) + \"            \" + str(cm[i][1][1]))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "576d78ea-8ef0-44db-a26d-af32118e4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the precision, recall, and f1 for each class in y\n",
    "# Arguments:\n",
    "# y_test (numpy.ndarray) --- The y (output) of the test set\n",
    "# y_pred (numpy.ndarray) --- The model's predicted output using X_test\n",
    "# *OPTIONAL* names (list) --- The name of each class\n",
    "def print_precision_recall(y_test, y_pred, names=[]):\n",
    "    print(\"PRECISION AND RECALL: ------------------------------------\")\n",
    "    if names:\n",
    "        print(classification_report(y_test, y_pred, target_names=names, zero_division=0))\n",
    "    else:\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2fab7f-68ea-4ce8-bc59-003ed75b524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the accuracy and MSE of the model's predictions\n",
    "# Arguments:\n",
    "# X_test (numpy.ndarray) --- The X (input) of the test set\n",
    "# y_test (numpy.ndarray) --- The y (output) of the test set\n",
    "# y_pred (numpy.ndarray) --- The model's predicted output using X_test\n",
    "def print_accuracy_mse(X_test, y_test, y_pred, model):\n",
    "    print(\"ACCURACY AND MSE: ----------------------------------------\")\n",
    "    print(\"Accuracy: \" + str(model.score(X_test, y_test)))\n",
    "    print(\"MSE: \" + str(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
